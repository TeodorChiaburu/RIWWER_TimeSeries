{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Time Series Forecast with NHiTS on the Vierlinden dataset (all sensors, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./pytorch-forecasting/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_forecasting import NHiTS, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "pl.seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Read the dataset into a DataFrame\n",
    "data = pd.read_csv('./RIWWER/Vierlinden/Vierlinden_2021_All.csv')\n",
    "\n",
    "# Drop columns that have lots of missing values\n",
    "data.drop([\"FLP_Hohenstand_Pumpensumpf_pval\",\"FLP_Strom_P3_pval\",\"FLP_Strom_P4_pval\",\"FLP_Strom_P5_pval\",\"Durchfluss SWP1 und SWP2_pval\",\"FLP_Hohenstand_Becken1_pval\",\"FLP_Hohenstand_Becken3_pval\",\"FLP_Hohenstand_Beckne2_pval\"], axis=1, inplace=True)\n",
    "\n",
    "# NaNs are not allowed by the model\n",
    "data.fillna(method=\"bfill\", inplace=True)\n",
    "data.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Set Datetime as index\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# One time series for the whole year?\n",
    "data['series'] = 0\n",
    "\n",
    "# As many timesteps per timeseries as hours in every month?\n",
    "time_idx = []\n",
    "for i in range(1):\n",
    "    timesteps = len( data[ data['series'] == i ] )\n",
    "    time_idx += list(range(timesteps))\n",
    "data['time_idx'] = time_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "             Datetime  Schieber Position_pval  Oberwasser_pval  \\\n0 2021-01-01 00:00:00                   100.0         8.140845   \n1 2021-01-01 01:00:00                   100.0         8.000000   \n2 2021-01-01 02:00:00                   100.0         7.967742   \n3 2021-01-01 03:00:00                   100.0         7.076923   \n4 2021-01-01 04:00:00                   100.0         8.464789   \n\n   Unterwasser_pval  Durchflumenge_pval  Berechnete Durchflussmenge_pval  \\\n0          5.753623            7.689189                         7.732558   \n1          5.173913            6.808219                         8.271739   \n2          5.000000            5.813333                         7.197674   \n3          4.843750            4.216216                         4.743243   \n4          5.466667            8.384615                         8.325000   \n\n   Fllstand SWS_pval  Fllstand RWS_pval  Strom P1_pval  Strom P2_pval  ...  \\\n0          75.717949               36.0       1.076923            0.0  ...   \n1          75.717949               36.0       1.076923            0.0  ...   \n2          75.717949               36.0       1.076923            0.0  ...   \n3          75.717949               36.0       1.076923            0.0  ...   \n4          75.717949               36.0       1.076923            0.0  ...   \n\n   Strom Pumpe 2_pval1  Strom Pumpe 3_pval  Niederschlag  Füllstand_RRB  \\\n0                  0.0                 1.0      0.000000           1.47   \n1                  0.0                 1.0      1.182353           1.47   \n2                  0.0                 1.0      1.182353           1.47   \n3                  0.0                 1.0      1.182353           1.47   \n4                  0.0                 1.0      1.182353           1.47   \n\n   Entleerung_RüB  Füllstand_RüB_1  Füllstand_RüB_2  Füllstand_RüB_3  series  \\\n0           0.098             3.16             3.08             2.72       0   \n1           0.099             3.16             3.08             2.72       0   \n2           0.096             3.16             3.08             2.72       0   \n3           0.098             3.16             3.08             2.72       0   \n4           0.098             3.16             3.08             2.72       0   \n\n   time_idx  \n0         0  \n1         1  \n2         2  \n3         3  \n4         4  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Schieber Position_pval</th>\n      <th>Oberwasser_pval</th>\n      <th>Unterwasser_pval</th>\n      <th>Durchflumenge_pval</th>\n      <th>Berechnete Durchflussmenge_pval</th>\n      <th>Fllstand SWS_pval</th>\n      <th>Fllstand RWS_pval</th>\n      <th>Strom P1_pval</th>\n      <th>Strom P2_pval</th>\n      <th>...</th>\n      <th>Strom Pumpe 2_pval1</th>\n      <th>Strom Pumpe 3_pval</th>\n      <th>Niederschlag</th>\n      <th>Füllstand_RRB</th>\n      <th>Entleerung_RüB</th>\n      <th>Füllstand_RüB_1</th>\n      <th>Füllstand_RüB_2</th>\n      <th>Füllstand_RüB_3</th>\n      <th>series</th>\n      <th>time_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-01-01 00:00:00</td>\n      <td>100.0</td>\n      <td>8.140845</td>\n      <td>5.753623</td>\n      <td>7.689189</td>\n      <td>7.732558</td>\n      <td>75.717949</td>\n      <td>36.0</td>\n      <td>1.076923</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.47</td>\n      <td>0.098</td>\n      <td>3.16</td>\n      <td>3.08</td>\n      <td>2.72</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-01-01 01:00:00</td>\n      <td>100.0</td>\n      <td>8.000000</td>\n      <td>5.173913</td>\n      <td>6.808219</td>\n      <td>8.271739</td>\n      <td>75.717949</td>\n      <td>36.0</td>\n      <td>1.076923</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.182353</td>\n      <td>1.47</td>\n      <td>0.099</td>\n      <td>3.16</td>\n      <td>3.08</td>\n      <td>2.72</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-01-01 02:00:00</td>\n      <td>100.0</td>\n      <td>7.967742</td>\n      <td>5.000000</td>\n      <td>5.813333</td>\n      <td>7.197674</td>\n      <td>75.717949</td>\n      <td>36.0</td>\n      <td>1.076923</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.182353</td>\n      <td>1.47</td>\n      <td>0.096</td>\n      <td>3.16</td>\n      <td>3.08</td>\n      <td>2.72</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-01-01 03:00:00</td>\n      <td>100.0</td>\n      <td>7.076923</td>\n      <td>4.843750</td>\n      <td>4.216216</td>\n      <td>4.743243</td>\n      <td>75.717949</td>\n      <td>36.0</td>\n      <td>1.076923</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.182353</td>\n      <td>1.47</td>\n      <td>0.098</td>\n      <td>3.16</td>\n      <td>3.08</td>\n      <td>2.72</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-01 04:00:00</td>\n      <td>100.0</td>\n      <td>8.464789</td>\n      <td>5.466667</td>\n      <td>8.384615</td>\n      <td>8.325000</td>\n      <td>75.717949</td>\n      <td>36.0</td>\n      <td>1.076923</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.182353</td>\n      <td>1.47</td>\n      <td>0.098</td>\n      <td>3.16</td>\n      <td>3.08</td>\n      <td>2.72</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Parameters for dataloaders\n",
    "max_encoder_length = 24*2\n",
    "max_prediction_length = 5*2\n",
    "training_cutoff = data[\"time_idx\"].max() * 4 // 5 # 80% for training\n",
    "context_length = max_encoder_length\n",
    "prediction_length = max_prediction_length\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchiaburu/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/tchiaburu/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# Load best model (from NHits_Vierlinden_Train.ipynb)\n",
    "best_model_path = './RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden_saved_datasets/lightning_logs/version_0/checkpoints/epoch=14-step=2250.ckpt'\n",
    "best_model = NHiTS.load_from_checkpoint(best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Corrupt sensor clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: there appears to be a problem with NHits when dealing with covariates. The prediction stays the same even when replacing all sensor values with 0!\n",
    "See issues:\n",
    "https://github.com/jdb78/pytorch-forecasting/issues/1065\n",
    "https://github.com/jdb78/pytorch-forecasting/issues/1071"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Sensor clusters\n",
    "# Weather and rain tanks: ['Niederschlag', 'Füllstand_RRB', 'Füllstand_RüB_1', 'Füllstand_RüB_2', 'Füllstand_RüB_3']\n",
    "sensors = {\n",
    "    \"Herzogstr\":     ['Schieber Position_pval', 'Oberwasser_pval', 'Unterwasser_pval', 'Durchflumenge_pval', 'Berechnete Durchflussmenge_pval'],\n",
    "    #\"Kaiserstr\":     ['Fllstand SWS_pval', 'Fllstand RWS_pval', 'Strom P1_pval', 'Strom P2_pval', 'Strom P3_pval', 'Strom P4_pval', 'Strom P5_pval', 'Strom P6_pval'],\n",
    "    #\"Kreuzweg\":      ['Fllstand Pumpensumpf_pval', 'Strom Pumpe 1_pval', 'Strom Pumpe 2_pval'],\n",
    "    #\"Vierlindenhof\": ['Fllstand Pumpensumpf_pval1', 'Strom Pumpe 1_pval1', 'Strom Pumpe 2_pval1', 'Strom Pumpe 3_pval']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++ Turning off Herzogstr ++++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechnete Durchflussmenge_pval\n",
      "MAE = tensor(1.4225, device='cuda:0')\n",
      "RMSE = tensor(8.2007, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Turn off sensors iteratively according to the cluster location\n",
    "for cluster in sensors:\n",
    "    print(\"\\n\\n++++++++++ Turning off \" + cluster + \" ++++++++++\\n\")\n",
    "\n",
    "    ### Create Dataloader for corrupted dataset ###\n",
    "    validation = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx > training_cutoff],\n",
    "        target_normalizer=\"auto\",\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"Entleerung_RüB\",\n",
    "        categorical_encoders={\"series\": NaNLabelEncoder().fit(data.series)},\n",
    "        group_ids=[\"series\"],\n",
    "        time_varying_unknown_reals=list(set(data.columns) - {'Datetime', 'series', 'time_idx'}),\n",
    "        max_encoder_length=context_length,\n",
    "        min_encoder_length=max_encoder_length,\n",
    "        max_prediction_length=prediction_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "    loaded_validation = validation.load('./RIWWER/Vierlinden/val_set')\n",
    "\n",
    "    # Note: After replacing the feature with zeros, the TimeSeriesDataset applies 'transform_values'\n",
    "    #       which leads to all the values in that column being replaced not by 0, but by another rescaled value\n",
    "    #       You may want to comment that line out in timeseries.py\n",
    "    for column in sensors[cluster]:\n",
    "        loaded_validation.set_overwrite_values(10, column, 'all')\n",
    "\n",
    "    val_dataloader = loaded_validation.to_dataloader(train=False, batch_size=batch_size, num_workers=18)\n",
    "\n",
    "    ### Make prediction and evaluate ###\n",
    "    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)]).to(torch.device('cuda:0'))\n",
    "    predictions = best_model.predict(val_dataloader,\n",
    "                                     trainer_kwargs=dict(default_root_dir=\"./RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden_saved_datasets\"))\n",
    "    print(column)\n",
    "    err = actuals - predictions\n",
    "    mae = err.abs().mean()\n",
    "    print('MAE = ' + str(mae))\n",
    "    rmse = torch.sqrt( torch.square(err).mean() )\n",
    "    print('RMSE = ' + str(rmse))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      time_first  time_last  time_diff_to_next  index_start  time  count  \\\n6960        6960       8759                  1            0  6960   1800   \n6961        6960       8759                  1            1  6961   1800   \n6962        6960       8759                  1            2  6962   1800   \n6963        6960       8759                  1            3  6963   1800   \n6964        6960       8759                  1            4  6964   1800   \n...          ...        ...                ...          ...   ...    ...   \n8698        6960       8759                  1         1738  8698   1800   \n8699        6960       8759                  1         1739  8699   1800   \n8700        6960       8759                  1         1740  8700   1800   \n8701        6960       8759                  1         1741  8701   1800   \n8702        6960       8759                  1         1742  8702   1800   \n\n      sequence_id  index_end  sequence_length  \n6960            0         57               58  \n6961            0         58               58  \n6962            0         59               58  \n6963            0         60               58  \n6964            0         61               58  \n...           ...        ...              ...  \n8698            0       1795               58  \n8699            0       1796               58  \n8700            0       1797               58  \n8701            0       1798               58  \n8702            0       1799               58  \n\n[1743 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_first</th>\n      <th>time_last</th>\n      <th>time_diff_to_next</th>\n      <th>index_start</th>\n      <th>time</th>\n      <th>count</th>\n      <th>sequence_id</th>\n      <th>index_end</th>\n      <th>sequence_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6960</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6960</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>57</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>6961</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6961</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>58</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>6962</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6962</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>59</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>6963</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6963</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>60</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>6964</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>4</td>\n      <td>6964</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>61</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8698</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1738</td>\n      <td>8698</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>1795</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>8699</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1739</td>\n      <td>8699</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>1796</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>8700</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1740</td>\n      <td>8700</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>1797</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>8701</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1741</td>\n      <td>8701</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>1798</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>8702</th>\n      <td>6960</td>\n      <td>8759</td>\n      <td>1</td>\n      <td>1742</td>\n      <td>8702</td>\n      <td>1800</td>\n      <td>0</td>\n      <td>1799</td>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n<p>1743 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_validation.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sensors shut down.\n",
      "MAE = tensor(1.4225, device='cuda:0')\n",
      "RMSE = tensor(8.2007, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sensors shut down.\n",
      "MAE = tensor(1.4225, device='cuda:0')\n",
      "RMSE = tensor(8.2007, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Exception ignored in: <function _releaseLock at 0x7fbb74b0eb60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tchiaburu/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 3611413, 3611449, 3611485, 3611521, 3611557, 3611593, 3611629, 3611665, 3611701, 3611737, 3611773, 3611809, 3611845, 3611881, 3611917) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1132\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/multiprocessing/queues.py:114\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[0;32m--> 114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "\u001B[0;31mEmpty\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m### Make prediction and evaluate ###\u001B[39;00m\n\u001B[1;32m      7\u001B[0m actuals \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([y[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(val_dataloader)])\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 8\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mtrainer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdefault_root_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden_saved_datasets\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m sensors shut down.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     11\u001B[0m err \u001B[38;5;241m=\u001B[39m actuals \u001B[38;5;241m-\u001B[39m predictions\n",
      "File \u001B[0;32m/mnt/KInsektDaten/teo/./pytorch-forecasting/pytorch_forecasting/models/base_model.py:1423\u001B[0m, in \u001B[0;36mBaseModel.predict\u001B[0;34m(self, data, mode, return_index, return_decoder_lengths, batch_size, num_workers, fast_dev_run, return_x, return_y, mode_kwargs, trainer_kwargs, write_interval, output_dir, **kwargs)\u001B[0m\n\u001B[1;32m   1421\u001B[0m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpytorch_lightning\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msetLevel(logging\u001B[38;5;241m.\u001B[39mWARNING)\n\u001B[1;32m   1422\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(fast_dev_run\u001B[38;5;241m=\u001B[39mfast_dev_run, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrainer_kwargs)\n\u001B[0;32m-> 1423\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1424\u001B[0m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlightning\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msetLevel(log_level_lighting)\n\u001B[1;32m   1425\u001B[0m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpytorch_lightning\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msetLevel(log_level_pytorch_lightning)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:843\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    841\u001B[0m     model \u001B[38;5;241m=\u001B[39m _maybe_unwrap_optimized(model)\n\u001B[1;32m    842\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 843\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:42\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     45\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:885\u001B[0m, in \u001B[0;36mTrainer._predict_impl\u001B[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mattach_data(model, predict_dataloaders\u001B[38;5;241m=\u001B[39mdataloaders, datamodule\u001B[38;5;241m=\u001B[39mdatamodule)\n\u001B[1;32m    882\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    883\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn, ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    884\u001B[0m )\n\u001B[0;32m--> 885\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:973\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    970\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    971\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 973\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    978\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1011\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1009\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_loop\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m-> 1011\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1012\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[1;32m   1013\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:177\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    175\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[0;32m--> 177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/loops/prediction_loop.py:110\u001B[0m, in \u001B[0;36m_PredictionLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 110\u001B[0m         batch, batch_idx, dataloader_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(data_fetcher)\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[1;32m    112\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict_step(batch, batch_idx, dataloader_idx)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:136\u001B[0m, in \u001B[0;36m_PrefetchDataFetcher.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;66;03m# this will run only when no pre-fetching was done.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 136\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;66;03m# consume the batch we just fetched\u001B[39;00m\n\u001B[1;32m    138\u001B[0m         batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatches\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:150\u001B[0m, in \u001B[0;36m_PrefetchDataFetcher._fetch_next_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_profiler()\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop_profiler()\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:284\u001B[0m, in \u001B[0;36mCombinedLoader.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 284\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator)\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator, _Sequential):\n\u001B[1;32m    286\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:123\u001B[0m, in \u001B[0;36m_Sequential.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    120\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 123\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterators[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    124\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_idx\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_idx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1145\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1144\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1145\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(pids_str)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 3611413, 3611449, 3611485, 3611521, 3611557, 3611593, 3611629, 3611665, 3611701, 3611737, 3611773, 3611809, 3611845, 3611881, 3611917) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for i in range(len(loaded_validation.data['reals'][0])):\n",
    "    loaded_validation.data['reals'][:, i] = 0.0\n",
    "\n",
    "    val_dataloader = loaded_validation.to_dataloader(train=False, batch_size=batch_size, num_workers=18)\n",
    "\n",
    "    ### Make prediction and evaluate ###\n",
    "    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)]).to(torch.device('cuda:0'))\n",
    "    predictions = best_model.predict(val_dataloader,\n",
    "                                     trainer_kwargs=dict(default_root_dir=\"./RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden_saved_datasets\"))\n",
    "    print(str(i+1) + ' sensors shut down.')\n",
    "    err = actuals - predictions\n",
    "    mae = err.abs().mean()\n",
    "    print('MAE = ' + str(mae))\n",
    "    rmse = torch.sqrt( torch.square(err).mean() )\n",
    "    print('RMSE = ' + str(rmse))\n",
    "    del val_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_validation.data['reals'][:, 0] = 0.0\n",
    "loaded_validation.data['reals']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_validation.time_varying_unknown_reals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in iter(val_dataloader):\n",
    "    t = x['encoder_cont'][0][0]\n",
    "    t[0] = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t[0] = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in iter(val_dataloader):\n",
    "    print(x['encoder_cont'][0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(x['encoder_cont'][0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in iter(val_dataloader):\n",
    "    for t in x['encoder_cont'][0][0]:\n",
    "        #t[0] = 0.0\n",
    "        print(t.item())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_validation._overwrite_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "riwwer_new",
   "language": "python",
   "display_name": "riwwer_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}