{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TIme Series Forecast with NHiTS on the Vierlinden dataset (all sensors, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./pytorch-forecasting/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_forecasting import NHiTS, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "pl.seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Read the dataset into a DataFrame\n",
    "data = pd.read_csv('./RIWWER/Vierlinden/Vierlinden_2021_All.csv')\n",
    "\n",
    "# Drop columns that have lots of missing values\n",
    "data.drop([\"FLP_Hohenstand_Pumpensumpf_pval\",\"FLP_Strom_P3_pval\",\"FLP_Strom_P4_pval\",\"FLP_Strom_P5_pval\",\"Durchfluss SWP1 und SWP2_pval\",\"FLP_Hohenstand_Becken1_pval\",\"FLP_Hohenstand_Becken3_pval\",\"FLP_Hohenstand_Beckne2_pval\"], axis=1, inplace=True)\n",
    "\n",
    "# NaNs are not allowed by the model\n",
    "data.fillna(method=\"bfill\", inplace=True)\n",
    "data.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Set Datetime as index\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# One time series for the whole year?\n",
    "data['series'] = 0\n",
    "\n",
    "# As many timesteps per timeseries as hours in every month?\n",
    "time_idx = []\n",
    "for i in range(1):\n",
    "    timesteps = len( data[ data['series'] == i ] )\n",
    "    time_idx += list(range(timesteps))\n",
    "data['time_idx'] = time_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Parameters for dataloaders\n",
    "max_encoder_length = 24*2\n",
    "max_prediction_length = 5*2\n",
    "training_cutoff = data[\"time_idx\"].max() * 4 // 5 # 80% for training\n",
    "context_length = max_encoder_length\n",
    "prediction_length = max_prediction_length\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchiaburu/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/tchiaburu/anaconda3/envs/torch_gpu_riwwer_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# Load best model (from NHits_Vierlinden_Train.ipynb)\n",
    "best_model_path = './RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden/lightning_logs/version_0/checkpoints/epoch=14-step=2250.ckpt'\n",
    "best_model = NHiTS.load_from_checkpoint(best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Corrupt sensor clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "fraction = 0.9   # fraction of rows to corrupt\n",
    "sampling = 'NAR' # sampling mechanism for corruptions, options are completely at random ('CAR'),\n",
    "                 # at random ('AR'), not at random ('NAR')\n",
    "\n",
    "# Sensor clusters\n",
    "# Weather and rain tanks: ['Niederschlag', 'Füllstand_RRB', 'Füllstand_RüB_1', 'Füllstand_RüB_2', 'Füllstand_RüB_3']\n",
    "sensors = {\n",
    "    \"Herzogstr\":     ['Schieber Position_pval', 'Oberwasser_pval', 'Unterwasser_pval', 'Durchflumenge_pval', 'Berechnete Durchflussmenge_pval'],\n",
    "    #\"Kaiserstr\":     ['Fllstand SWS_pval', 'Fllstand RWS_pval', 'Strom P1_pval', 'Strom P2_pval', 'Strom P3_pval', 'Strom P4_pval', 'Strom P5_pval', 'Strom P6_pval'],\n",
    "    #\"Kreuzweg\":      ['Fllstand Pumpensumpf_pval', 'Strom Pumpe 1_pval', 'Strom Pumpe 2_pval'],\n",
    "    #\"Vierlindenhof\": ['Fllstand Pumpensumpf_pval1', 'Strom Pumpe 1_pval1', 'Strom Pumpe 2_pval1', 'Strom Pumpe 3_pval']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++ Turning off Herzogstr ++++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = tensor(3.1364, device='cuda:0')\n",
      "RMSE = tensor(11.1946, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Turn off sensors iteratively according to the cluster location\n",
    "for cluster in sensors:\n",
    "    print(\"\\n\\n++++++++++ Turning off \" + cluster + \" ++++++++++\\n\")\n",
    "\n",
    "    # Copy dataset (we want to investigate what impact the turning off of individual clusters has)\n",
    "    data_copy = data.copy(deep=True)\n",
    "\n",
    "    ### Sample rows and corrupt them ###\n",
    "    for column in sensors[cluster]:\n",
    "        if fraction == 1.0:\n",
    "            rows = data_copy.index\n",
    "        # Completely At Random\n",
    "        elif sampling == 'CAR':\n",
    "            rows = np.random.permutation(data_copy.index)[:int(len(data_copy)*fraction)]\n",
    "        elif sampling == 'NAR' or sampling == 'AR':\n",
    "            n_values_to_discard = int(len(data_copy) * min(fraction, 1.0))\n",
    "            perc_lower_start = np.random.randint(0, len(data_copy) - n_values_to_discard)\n",
    "            perc_idx = range(perc_lower_start, perc_lower_start + n_values_to_discard)\n",
    "            # Not At Random\n",
    "            if sampling == 'NAR':\n",
    "                # pick a random percentile of values in this column\n",
    "                rows = data_copy[column].sort_values().iloc[perc_idx].index\n",
    "            # At Random\n",
    "            elif sampling == 'AR':\n",
    "                depends_on_col = np.random.choice(list(set(data_copy.columns) - {column}))\n",
    "                # pick a random percentile of values in other column\n",
    "                rows = data_copy[depends_on_col].sort_values().iloc[perc_idx].index\n",
    "        # Overwrite values with 0 (random value better?)\n",
    "        data_copy.loc[rows, column] = 0.0\n",
    "\n",
    "    ### Create Dataloader for corrupted dataset ###\n",
    "    training = TimeSeriesDataSet(\n",
    "        data_copy[lambda x: x.time_idx <= training_cutoff],\n",
    "        target_normalizer=\"auto\",\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"Entleerung_RüB\",\n",
    "        categorical_encoders={\"series\": NaNLabelEncoder().fit(data_copy.series)},\n",
    "        group_ids=[\"series\"],\n",
    "        time_varying_unknown_reals=list(set(data_copy.columns) - {'Datetime', 'series', 'time_idx'}),\n",
    "        max_encoder_length=context_length,\n",
    "        min_encoder_length=max_encoder_length,\n",
    "        max_prediction_length=prediction_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data_copy, min_prediction_idx=training_cutoff + 1, stop_randomization=True)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=18)\n",
    "\n",
    "    ### Make prediction and evaluate ###\n",
    "    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)]).to(torch.device('cuda:0'))\n",
    "    predictions = best_model.predict(val_dataloader,\n",
    "                                     trainer_kwargs=dict(default_root_dir=\"./RIWWER/torch_forecasting/model_checkpoints/NHits_Vierlinden\"))\n",
    "    err = actuals - predictions\n",
    "    mae = err.abs().mean()\n",
    "    print('MAE = ' + str(mae))\n",
    "    rmse = torch.sqrt( torch.square(err).mean() )\n",
    "    print('RMSE = ' + str(rmse))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "riwwer_new",
   "language": "python",
   "display_name": "riwwer_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}